<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>stream learning | Jacob ML</title><link>https://jacobmontiel.github.io/tag/stream-learning/</link><atom:link href="https://jacobmontiel.github.io/tag/stream-learning/index.xml" rel="self" type="application/rss+xml"/><description>stream learning</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>© Jacob Montiel</copyright><lastBuildDate>Fri, 25 Oct 2019 00:00:00 +0000</lastBuildDate><image><url>https://jacobmontiel.github.io/media/icon_hucbf789615b40e761c3a2025b00d1b297_56858_512x512_fill_lanczos_center_2.png</url><title>stream learning</title><link>https://jacobmontiel.github.io/tag/stream-learning/</link></image><item><title>Interview on adaptive learning</title><link>https://jacobmontiel.github.io/post/2019-10-25-interview/</link><pubDate>Fri, 25 Oct 2019 00:00:00 +0000</pubDate><guid>https://jacobmontiel.github.io/post/2019-10-25-interview/</guid><description>&lt;p>My interview on the benefits of adaptive learning methods has been published in a white-book by &lt;a href="https://www.quantmetry.com/" target="_blank" rel="noopener">Quantmetry&lt;/a>.&lt;/p>
&lt;p>The white-book, No. 5 &amp;ldquo;AI en production&amp;rdquo;, is free to download &lt;a href="https://www.quantmetry.com/les-livres-blancs/" target="_blank" rel="noopener">here&lt;/a>.&lt;/p>
&lt;hr>
&lt;h3 id="transcript-of-the-interview">Transcript of the interview&lt;/h3>
&lt;p>(in french)&lt;/p>
&lt;h4 id="quest-ce-quune-dérive-">Qu’est-ce qu’une dérive ?&lt;/h4>
&lt;p>L’apprentissage est souvent considéré comme une tâche statique. Cependant, en conditions réelles, les données évoluent constamment. C’est ce qu’on appelle une dérive conceptuelle. Par exemple, les marchés financiers sont instables : les risques de crédit ne sont pas les mêmes d’une année sur l’autre.
Quelles conséquences pour les modèles classiques ?
Les modèles standards ont toutes les chances d’échouer, car ils ignorent complètement ce phénomène. Souvent, on développe un modèle et, après l’avoir fait fonctionner une fois, on pense que le travail est terminé. En réalité, il faut toujours évaluer la performance du modèle en production au cours du temps et évaluer s’il est sujet à une dérive.&lt;/p>
&lt;h4 id="quelles-sont-les-solutions-">Quelles sont les solutions ?&lt;/h4>
&lt;p>Ce phénomène a été largement étudié dans la littérature sur le stream mining, où plusieurs solutions ont été proposées. Dans ce cadre, les modèles s’adaptent au fur et à mesure. En effet, certaines méthodes permettent de détecter automatiquement les changements dans les données en surveillant la performance des modèles. Elles permettent d’indiquer : &amp;ldquo;attention, un changement est en train de s’opérer, il faut réagir maintenant&amp;rdquo;. L’idée est ensuite de créer des modèles qui s’adaptent rapidement aux changements. Par exemple, si une dérive est détectée, on peut rejeter un modèle obsolète et déclencher l’apprentissage d’un nouveau modèle.&lt;/p>
&lt;h4 id="peut-on-utiliser-ces-techniques-quand-les-données-arrivent-par-cohorte-">Peut-on utiliser ces techniques quand les données arrivent par cohorte ?&lt;/h4>
&lt;p>Pas directement, car dans ce cas, il faut attendre entre deux acquisitions successives de données. C’est en effet caractéristique de l’approche statique, car sous l’hypothèse de données identiquement distribuées, il est avantageux d’accumuler autant de données que possible. En stream mining, cette phase d’accumulation n’a pas lieu d’être, il n’y a même pas de problématique de stockage car la donnée est exploitée à la volée. De toute façon, pour être réactif et adaptatif, il vaut mieux attendre le moins longtemps possible. Ceci étant dit, des recherches en cours étudient des systèmes hybrides, où une brique statique et une brique adaptative peuvent collaborer.&lt;/p>
&lt;h4 id="quels-sont-les-outils-dédiés-à-lapprentissage-adaptatif-">Quels sont les outils dédiés à l’apprentissage adaptatif ?&lt;/h4>
&lt;p>Il y a des initiatives comme MOA (Massive Online Analysis), écrit en Java, et scikit-multiflow, écrit en Python. Les deux librairies sont en accès libre et implémentent l’état de l’art des algorithmes adaptatifs en stream mining. Elles ont été développées par des chercheurs mais conçues pour les professionnels. Quelques fournisseurs Cloud proposent également des solutions optimisées pour les flux de données, mais la plupart ignorent le problème de la dérive.&lt;/p>
&lt;h4 id="lapprentissage-adaptatif-est-il-crucial-pour-lintelligence-artificielle-en-production-">L’apprentissage adaptatif est-il crucial pour l’intelligence artificielle en production ?&lt;/h4>
&lt;p>Dans l’industrie, on ne peut pas toujours reproduire ce qui se fait ailleurs car ce qui fonctionne bien dans un cas peut ne pas fonctionner dans une autre. La clef est vraiment de comprendre en profondeur la donnée, de travailler par itération, d’essayer différentes techniques. La solution est toujours personnalisée et particulière au problème traité. Si la donnée évolue par nature et est produite en masse, alors l’apprentissage adaptatif est en effet très prometteur. Dans ce contexte, il fournit les meilleurs performances et la gestion de ressources informatiques la plus efficace.&lt;/p>
&lt;h4 id="pourquoi-y-a-t-il-un-tel-écart-entre-les-pratiques-universitaires-et-industrielles-">Pourquoi y a-t-il un tel écart entre les pratiques universitaires et industrielles ?&lt;/h4>
&lt;p>Les cycles de développement sont relativement différents. En recherche, il est naturel d’aller toujours plus loin, d’expérimenter et d’échouer. L’industrie est plus prudente, et requiert des solutions non seulement efficaces mais également stables, car les enjeux sont bien plus sensibles. L’industrie utilise ce qui marche dans son contexte et l’adapte à son besoin. Ces deux mondes évoluent dans des directions complémentaires. A n’en pas douter, toute collaboration entre universitaires et industriels est bénéfique pour les deux.&lt;/p></description></item><item><title>Research fellow at the University of Waikato</title><link>https://jacobmontiel.github.io/post/2019-04-01-research-fellow/</link><pubDate>Sun, 01 Sep 2019 00:00:00 +0000</pubDate><guid>https://jacobmontiel.github.io/post/2019-04-01-research-fellow/</guid><description>&lt;p>I have started a new potion as Research Fellow in the &lt;a href="https://www.cs.waikato.ac.nz/~ml/index.html" target="_blank" rel="noopener">Machine Learning Group&lt;/a> at the University of Waikato in New Zealand.&lt;/p></description></item><item><title>Postdoc at Télécom ParisTech</title><link>https://jacobmontiel.github.io/post/2019-04-01-postdoc/</link><pubDate>Mon, 01 Apr 2019 00:00:00 +0000</pubDate><guid>https://jacobmontiel.github.io/post/2019-04-01-postdoc/</guid><description>&lt;p>I have started a new potion as Postdoc at the &lt;a href="https://dig.telecom-paristech.fr/blog/" target="_blank" rel="noopener">Data, Intelligence and Graphs&lt;/a> (DIG) group at Télécom ParisTech.&lt;/p></description></item><item><title>I got my PhD</title><link>https://jacobmontiel.github.io/post/2019-03-07-phd_defense/</link><pubDate>Thu, 07 Mar 2019 00:00:00 +0000</pubDate><guid>https://jacobmontiel.github.io/post/2019-03-07-phd_defense/</guid><description>&lt;p>I have successfully defended my PhD thesis &amp;ldquo;Fast and Slow Machine Learning&amp;rdquo;.&lt;/p>
&lt;p>Jury:\&lt;br>
M João Gama, &lt;em>University of Porto&lt;/em>\&lt;br>
M Georges Hébrail, &lt;em>Électricité de France&lt;/em>\&lt;br>
M Themis Palpanas, &lt;em>Université Paris Descartes&lt;/em>\&lt;br>
M Ricard Gavaldà, &lt;em>Universitat Politècnica de Catalunya&lt;/em>\&lt;br>
M Jesse Read, &lt;em>École Polytechnique&lt;/em>\&lt;br>
M Albert Bifet, &lt;em>Télécom ParisTech (Directeur de recherche)&lt;/em>\&lt;br>
M Talel Abdessalem, &lt;em>Télécom ParisTech (Directeur de thèse)&lt;/em>&lt;/p></description></item><item><title>IEEE BigData 2018</title><link>https://jacobmontiel.github.io/post/2018-12-10-ieee-bigdata/</link><pubDate>Mon, 10 Dec 2018 00:00:00 +0000</pubDate><guid>https://jacobmontiel.github.io/post/2018-12-10-ieee-bigdata/</guid><description>&lt;p>I am attending the &lt;a href="http://cci.drexel.edu/bigdata/bigdata2018/" target="_blank" rel="noopener">2018 IEEE International Conference on Big Data&lt;/a> in Settle, USA, to present our paper&lt;/p>
&lt;p>&lt;strong>&lt;a href="https://ieeexplore.ieee.org/document/8622222" target="_blank" rel="noopener">Learning Fast and Slow: A Unified Batch/Stream Framework.&lt;/a>&lt;/strong>.&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>
Data ubiquity highlights the need of efficient and adaptable data-driven solutions. In this paper, we present FAST AND SLOW LEARNING (FSL), a novel unified framework that sheds light on the symbiosis between batch and stream learning. FSL works by employing Fast (stream) and Slow (batch) Learners, emulating the mechanisms used by humans to make decisions. We showcase the applicability of FSL on the task of classification by introducing the FAST AND SLOW CLASSIFIER (FSC). A Fast Learner provides predictions on the spot, continuously updating its model and adapting to changes in the data. On the other hand, the Slow Learner provides predictions considering a wider spectrum of seen data, requiring more time and data to create complex models. Once that enough data has been collected, FSC trains the Slow Learner and starts tracking the performance of both learners. A drift detection mechanism triggers the creation of new Slow models when the current Slow model becomes obsolete. FSC selects between Fast and Slow Learners according to their performance on new incoming data. Test results on real and synthetic data show that FSC effectively drives the positive interaction of stream and batch models for learning from evolving data streams.&lt;/p></description></item><item><title>IEEE BigData 2017</title><link>https://jacobmontiel.github.io/post/2017-12-11-ieee-bigdata/</link><pubDate>Mon, 11 Dec 2017 00:00:00 +0000</pubDate><guid>https://jacobmontiel.github.io/post/2017-12-11-ieee-bigdata/</guid><description>&lt;p>I am attending the &lt;a href="http://cci.drexel.edu/bigdata/bigdata2017/index.html" target="_blank" rel="noopener">2017 IEEE International Conference on Big Data&lt;/a> in Boston, Massachusetts, to present our paper&lt;/p>
&lt;p>&lt;strong>&lt;a href="http://ieeexplore.ieee.org/document/8258084/" target="_blank" rel="noopener">Predicting over-indebtedness on batch and streaming data&lt;/a>&lt;/strong>.&lt;/p>
&lt;p>&lt;strong>Abstract:&lt;/strong>
Detecting over-indebtedness, the difficulties meeting household payment commitments, poses multiple Big Data challenges for banking institutions. We present a novel data-driven framework for predicting over-indebtedness on real-world data. A warning mechanism that generates predictions 6 months ahead, improving the chances of financial recovery. This framework is based on the combination of feature selection and supervised learning techniques, and uses data balancing for fine-tuning the predictive models. We propose two versions of the framework based on state-of-the-art batch and streaming learning techniques. To the best of our knowledge, the proposed framework is the first to cast over-indebtedness prediction as a stream learning problem. The appeal of stream learning rises from the large amount of data continuously generated, and the fact that batch models become obsolete over time as financial data evolves, while stream models are continuously updated as new data is available. We use credit data from two banks from the Groupe BPCE (the second-largest banking institution in France) and apply multi-metric criteria to evaluate model performance and fairness. Test results show the framework&amp;rsquo;s interbank applicability and that the proposed batch and stream frameworks outperform the current solution for both single and multi-metric criteria. Additionally, the generic structure of the framework serves as a template for systematically approaching similar classification problems.&lt;/p></description></item></channel></rss>